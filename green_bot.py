import os
import requests
import numpy as np
import tensorflow as tf
import json
from flask import Flask, request
from twilio.twiml.messaging_response import MessagingResponse
from pathlib import Path
from PIL import Image
from io import BytesIO
import gdown
import zipfile
from collections import OrderedDict
import gc

# --- CONFIGURATION ---
app = Flask(__name__)

# Download models from Dropbox
def download_models_from_dropbox():
    models_dir = Path('models')
    if models_dir.exists() and len(list(models_dir.glob('*.keras'))) >= 18:
        print("âœ… Models exist")
        return
    
    print("ğŸ“¥ Downloading models from Dropbox...")
    
    # Your Dropbox direct download link (change dl=0 to dl=1)
    DROPBOX_URL = "https://www.dropbox.com/scl/fi/1qhklwrp1qxe8cvsa0zf9/models.zip?rlkey=69s5wrz9kjg9dkb7yhkjz45xa&st=djrc963c&dl=1"  # Replace with your Dropbox link
    
    try:
        print("Downloading... (this may take 5-10 minutes)")
        
        response = requests.get(DROPBOX_URL, stream=True)
        
        with open("models.zip", 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                f.write(chunk)
        
        print("âœ… Download complete!")
        
        # Extract
        with zipfile.ZipFile("models.zip", 'r') as z:
            z.extractall('.')
        os.remove("models.zip")
        print("âœ… Models ready!")
        
    except Exception as e:
        print(f"âŒ Error: {e}")

# Paths
BASE_DIR = Path('.')
MODELS_DIR = BASE_DIR / 'models'

# Download models on startup
download_models_from_dropbox()

# Check for local files
if Path('disease_translations.json').exists():
    TRANSLATIONS_FILE = Path('disease_translations.json')
else:
    TRANSLATIONS_FILE = BASE_DIR / 'disease_translations.json'

if Path('class_indices.json').exists():
    INDICES_FILE = Path('class_indices.json')
else:
    INDICES_FILE = BASE_DIR / 'class_indices.json'

# Global Cache with LRU
MAX_MODELS = 10  # Keep max 10 models in memory
loaded_models = OrderedDict()
class_indices = {}
translations = {}

# --- LOAD RESOURCES ---
def load_resources():
    global class_indices, translations
    
    if TRANSLATIONS_FILE.exists():
        with open(TRANSLATIONS_FILE, 'r', encoding='utf-8') as f:
            translations = json.load(f)
        print("âœ… Translations Loaded")
    
    if INDICES_FILE.exists():
        with open(INDICES_FILE, 'r') as f:
            class_indices = json.load(f)
        print(f"âœ… Class Indices Loaded: {len(class_indices)} models")

# --- MODEL LOADING WITH LRU CACHE ---
def get_model(model_name):
    """Load model with LRU cache - keeps max 10 models in memory"""
    
    # If already loaded, move to end (most recent)
    if model_name in loaded_models:
        loaded_models.move_to_end(model_name)
        print(f"â™»ï¸ Using cached model: {model_name}")
        return loaded_models[model_name]
    
    model_path = MODELS_DIR / f"{model_name}_final.keras"
    
    if not model_path.exists():
        print(f"âŒ Model not found: {model_path}")
        return None
    
    # Remove oldest model if at limit
    if len(loaded_models) >= MAX_MODELS:
        oldest = next(iter(loaded_models))
        print(f"ğŸ—‘ï¸ Removing old model: {oldest} (freeing memory)")
        del loaded_models[oldest]
        gc.collect()  # Force garbage collection
    
    # Load new model
    print(f"ğŸ“¥ Loading model: {model_name}... ({len(loaded_models)+1}/{MAX_MODELS})")
    model = tf.keras.models.load_model(model_path)
    loaded_models[model_name] = model
    print(f"âœ… Model loaded: {model_name}")
    
    return model

# --- PREDICTION ---
def predict_image(model, img_data, model_name):
    img = Image.open(BytesIO(img_data)).convert('RGB').resize((224, 224))
    img_array = np.array(img).astype('float32')
    img_array = np.expand_dims(img_array, axis=0)
    img_array = tf.keras.applications.efficientnet.preprocess_input(img_array)
    
    predictions = model.predict(img_array, verbose=0)
    predicted_class_idx = np.argmax(predictions[0])
    confidence = float(predictions[0][predicted_class_idx] * 100)
    
    indices = class_indices.get(model_name, {})
    english_label = indices.get(str(predicted_class_idx), f"Class_{predicted_class_idx}")
    
    crop_name = model_name.replace('_', ' ').title()
    arabic_label = english_label
    
    if crop_name in translations and english_label in translations[crop_name]:
        arabic_label = translations[crop_name][english_label]
        
    return arabic_label, confidence

# --- WHATSAPP BOT ---
user_sessions = {}

@app.route('/whatsapp', methods=['POST'])
def whatsapp_reply():
    try:
        print("ğŸ”µ Request received!")
        incoming_msg = request.values.get('Body', '').strip().lower()
        sender = request.values.get('From', '')
        num_media = int(request.values.get('NumMedia', 0))
        
        print(f"ğŸ“± From: {sender}")
        print(f"ğŸ“ Message: {incoming_msg}")
        print(f"ğŸ“¸ Media count: {num_media}")
    
    resp = MessagingResponse()
    msg = resp.message()
    
    # GREETING
    if incoming_msg in ['hi', 'hello', 'Ù‡Ù„Ø§', 'Ø³Ù„Ø§Ù…', 'Ø¨Ø¯Ø§ÙŠØ©', 'start', 'menu']:
        user_sessions.pop(sender, None)
        msg.body("ğŸŒ¿ *Ø£Ù‡Ù„Ø§Ù‹ Ø¨Ùƒ ÙÙŠ Ø·Ø¨ÙŠØ¨ Ø§Ù„Ù†Ø¨Ø§ØªØ§Øª Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ!* ğŸ‡¸ğŸ‡¦\n\nØ§Ø®ØªØ± Ø§Ù„Ù…Ø­ØµÙˆÙ„ (Ø£Ø±Ø³Ù„ Ø§Ù„Ø±Ù‚Ù…): ğŸ‘‡\n\n" +
                 "1. ğŸŒ´ Ù†Ø®ÙŠÙ„ - Ø£ÙˆØ±Ø§Ù‚\n" +
                 "2. ğŸŠ Ø­Ù…Ø¶ÙŠØ§Øª - Ø«Ù…Ø§Ø±\n" +
                 "3. ğŸƒ Ø­Ù…Ø¶ÙŠØ§Øª - Ø£ÙˆØ±Ø§Ù‚\n" +
                 "4. ğŸ… Ø·Ù…Ø§Ø·Ù… - Ø£ÙˆØ±Ø§Ù‚\n" +
                 "5. ğŸ¥” Ø¨Ø·Ø§Ø·Ø³ - Ø£ÙˆØ±Ø§Ù‚\n" +
                 "6. ğŸ¥’ Ø®ÙŠØ§Ø± - Ø£ÙˆØ±Ø§Ù‚\n" +
                 "7. ğŸŒ½ Ø°Ø±Ø© - Ø£ÙˆØ±Ø§Ù‚\n" +
                 "8. ğŸ‡ Ø¹Ù†Ø¨ - Ø£ÙˆØ±Ø§Ù‚\n" +
                 "9. ğŸ Ø±Ù…Ø§Ù† - Ø«Ù…Ø§Ø±\n" +
                 "10. ğŸ¥¬ Ø®Ø³ - Ø£ÙˆØ±Ø§Ù‚\n" +
                 "11. ğŸŒ¾ Ù‚Ù…Ø­ - Ø£ÙˆØ±Ø§Ù‚\n" +
                 "12. ğŸ¥­ Ù…Ø§Ù†Ø¬Ùˆ - Ø£ÙˆØ±Ø§Ù‚\n" +
                 "13. ğŸŒ Ù…ÙˆØ² - Ø«Ù…Ø§Ø±\n" +
                 "14. ğŸƒ Ù…ÙˆØ² - Ø£ÙˆØ±Ø§Ù‚\n" +
                 "15. ğŸ«˜ ÙØ§ØµÙˆÙ„ÙŠØ§ - Ø£ÙˆØ±Ø§Ù‚\n" +
                 "16. ğŸ† Ø¨Ø§Ø°Ù†Ø¬Ø§Ù† - Ø£ÙˆØ±Ø§Ù‚\n" +
                 "17. ğŸ¥— Ù…Ù„ÙÙˆÙ - Ø£ÙˆØ±Ø§Ù‚\n" +
                 "18. ğŸŒ¶ï¸ ÙÙ„ÙÙ„ - Ø£ÙˆØ±Ø§Ù‚")
        return str(resp)

    # CROP SELECTION
    crop_map = {
        '1': 'date_palm_leaves', '2': 'citrus_fruits', '3': 'citrus_leaves',
        '4': 'tomato_leaves', '5': 'potato_leaves', '6': 'cucumber_leaves',
        '7': 'corn_leaves', '8': 'grape_leaves', '9': 'pomegranate_fruits',
        '10': 'lettuce_leaves', '11': 'wheat_leaves', '12': 'mango_leaves',
        '13': 'banana_fruits', '14': 'banana_leaves', '15': 'bean_leaves',
        '16': 'eggplant_leaves', '17': 'cabbage_leaves', '18': 'pepper_leaves'
    }
    
    if incoming_msg in crop_map:
        selected_crop = crop_map[incoming_msg]
        user_sessions[sender] = selected_crop
        
        crop_display = {
            'date_palm_leaves': 'Ù†Ø®ÙŠÙ„ - Ø£ÙˆØ±Ø§Ù‚', 'citrus_fruits': 'Ø­Ù…Ø¶ÙŠØ§Øª - Ø«Ù…Ø§Ø±',
            'citrus_leaves': 'Ø­Ù…Ø¶ÙŠØ§Øª - Ø£ÙˆØ±Ø§Ù‚', 'tomato_leaves': 'Ø·Ù…Ø§Ø·Ù… - Ø£ÙˆØ±Ø§Ù‚',
            'potato_leaves': 'Ø¨Ø·Ø§Ø·Ø³ - Ø£ÙˆØ±Ø§Ù‚', 'cucumber_leaves': 'Ø®ÙŠØ§Ø± - Ø£ÙˆØ±Ø§Ù‚',
            'corn_leaves': 'Ø°Ø±Ø© - Ø£ÙˆØ±Ø§Ù‚', 'grape_leaves': 'Ø¹Ù†Ø¨ - Ø£ÙˆØ±Ø§Ù‚',
            'pomegranate_fruits': 'Ø±Ù…Ø§Ù† - Ø«Ù…Ø§Ø±', 'lettuce_leaves': 'Ø®Ø³ - Ø£ÙˆØ±Ø§Ù‚',
            'wheat_leaves': 'Ù‚Ù…Ø­ - Ø£ÙˆØ±Ø§Ù‚', 'mango_leaves': 'Ù…Ø§Ù†Ø¬Ùˆ - Ø£ÙˆØ±Ø§Ù‚',
            'banana_fruits': 'Ù…ÙˆØ² - Ø«Ù…Ø§Ø±', 'banana_leaves': 'Ù…ÙˆØ² - Ø£ÙˆØ±Ø§Ù‚',
            'bean_leaves': 'ÙØ§ØµÙˆÙ„ÙŠØ§ - Ø£ÙˆØ±Ø§Ù‚', 'eggplant_leaves': 'Ø¨Ø§Ø°Ù†Ø¬Ø§Ù† - Ø£ÙˆØ±Ø§Ù‚',
            'cabbage_leaves': 'Ù…Ù„ÙÙˆÙ - Ø£ÙˆØ±Ø§Ù‚', 'pepper_leaves': 'ÙÙ„ÙÙ„ - Ø£ÙˆØ±Ø§Ù‚'
        }
        
        crop_name = crop_display.get(selected_crop, selected_crop)
        sample_type = 'Ø§Ù„Ø«Ù…Ø±Ø©' if 'fruits' in selected_crop else 'Ø§Ù„ÙˆØ±Ù‚Ø©'
        msg.body(f"âœ… ØªÙ… Ø§Ø®ØªÙŠØ§Ø±: *{crop_name}*.\n\nğŸ“¸ *Ø§Ù„Ø¢Ù†ØŒ Ø£Ø±Ø³Ù„ ØµÙˆØ±Ø© {sample_type} Ø§Ù„Ù…ØµØ§Ø¨Ø©.*")
        return str(resp)
    
    # IMAGE HANDLING
    if num_media > 0:
        current_crop = user_sessions.get(sender)
        
        if not current_crop:
            msg.body("âš ï¸ *Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…Ø­ØµÙˆÙ„ Ø£ÙˆÙ„Ø§Ù‹!* \nØ£Ø±Ø³Ù„ ÙƒÙ„Ù…Ø© 'Ù‡Ù„Ø§' Ù„Ù„Ø¨Ø¯Ø¡.")
            return str(resp)
            
        image_url = request.values.get('MediaUrl0')
        
        try:
            print(f"ğŸ“¥ Downloading: {image_url}")
            TWILIO_SID = os.getenv('TWILIO_SID')
            TWILIO_TOKEN = os.getenv('TWILIO_TOKEN')
            
            response = requests.get(image_url, auth=(TWILIO_SID, TWILIO_TOKEN), allow_redirects=True)
            
            if response.status_code != 200:
                msg.body("âŒ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©.")
                return str(resp)
            
            img_data = response.content
            print(f"   âœ… Downloaded {len(img_data)} bytes")
            
            model = get_model(current_crop)
            if not model:
                msg.body("âŒ Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ØºÙŠØ± Ù…ØªÙˆÙØ± Ø­Ø§Ù„ÙŠØ§Ù‹.")
                return str(resp)
                
            print(f"ğŸ”¬ Analyzing image...")
            diagnosis, conf = predict_image(model, img_data, current_crop)
            print(f"   âœ… Result: {diagnosis} ({conf:.1f}%)")
            
            # Build result text
            result_text = f"ğŸ” *Ø§Ù„ØªØ´Ø®ÙŠØµ:* {diagnosis}\nğŸ¯ *Ø§Ù„Ø¯Ù‚Ø©:* {conf:.1f}%\n\n"
            
            if conf < 60:
                result_text += "âš ï¸ *Ù…Ù„Ø§Ø­Ø¸Ø©:* Ù„Ø³Øª Ù…ØªØ£ÙƒØ¯Ø§Ù‹ ØªÙ…Ø§Ù…Ø§Ù‹. ÙŠØ±Ø¬Ù‰ Ø§Ø³ØªØ´Ø§Ø±Ø© Ù…Ù‡Ù†Ø¯Ø³ Ø²Ø±Ø§Ø¹ÙŠ."
            else:
                result_text += "âœ… *Ø§Ù„ØªØ´Ø®ÙŠØµ Ù…ÙˆØ«ÙˆÙ‚.*"
            
            # Send reply with error handling
            try:
                msg.body(result_text)
                print(f"âœ… Sent reply successfully")
            except Exception as reply_error:
                print(f"âŒ Failed to send reply: {reply_error}")
                # Try simpler message
                msg.body(f"Ø§Ù„ØªØ´Ø®ÙŠØµ: {diagnosis}\nØ§Ù„Ø¯Ù‚Ø©: {conf:.1f}%")
            
        except Exception as e:
            print(f"âŒ Error during processing: {e}")
            import traceback
            traceback.print_exc()
            msg.body("âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©. Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.")
            
        return str(resp)

    # FALLBACK
    msg.body("ğŸ¤– Ù„Ù… Ø£ÙÙ‡Ù… Ø±Ø³Ø§Ù„ØªÙƒ. Ø£Ø±Ø³Ù„ 'Ù‡Ù„Ø§' Ù„Ù„Ø¨Ø¯Ø¡.")
    return str(resp)
    
    except Exception as e:
        print(f"ğŸ”´ CRITICAL ERROR in whatsapp_reply: {e}")
        import traceback
        traceback.print_exc()
        resp = MessagingResponse()
        resp.message("âŒ Ø­Ø¯Ø« Ø®Ø·Ø£. Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.")
        return str(resp)

@app.route('/health')
def health():
    return 'OK', 200

if __name__ == '__main__':
    load_resources()
    app.run(port=5000)
