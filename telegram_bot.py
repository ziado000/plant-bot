import os
import requests
import numpy as np
import tensorflow as tf
import json
from pathlib import Path
from PIL import Image
from io import BytesIO
from collections import OrderedDict
import gc
import zipfile
import threading

# Telegram imports
from telegram import Update, ReplyKeyboardMarkup, ReplyKeyboardRemove
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes

# Flask for health check
from flask import Flask

# Download models from Dropbox
def download_models_from_dropbox():
    models_dir = Path('models')
    if models_dir.exists() and len(list(models_dir.glob('*.keras'))) >= 18:
        print("âœ… Models exist")
        return
    
    print("ğŸ“¥ Downloading models from Dropbox...")
    
    # Your Dropbox direct download link (change dl=0 to dl=1)
    DROPBOX_URL = "https://www.dropbox.com/scl/fi/1qhklwrp1qxe8cvsa0zf9/models.zip?rlkey=69s5wrz9kjg9dkb7yhkjz45xa&st=djrc963c&dl=1"
    
    try:
        print("Downloading... (this may take 5-10 minutes)")
        
        response = requests.get(DROPBOX_URL, stream=True)
        
        with open("models.zip", 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                f.write(chunk)
        
        print("âœ… Download complete!")
        
        # Extract
        with zipfile.ZipFile("models.zip", 'r') as z:
            z.extractall('.')
        os.remove("models.zip")
        print("âœ… Models ready!")
        
    except Exception as e:
        print(f"âŒ Error: {e}")

# Paths
BASE_DIR = Path('.')
MODELS_DIR = BASE_DIR / 'models'

# Download models on startup
download_models_from_dropbox()

# Check for local files
if Path('disease_translations.json').exists():
    TRANSLATIONS_FILE = Path('disease_translations.json')
else:
    TRANSLATIONS_FILE = BASE_DIR / 'disease_translations.json'

if Path('class_indices.json').exists():
    INDICES_FILE = Path('class_indices.json')
else:
    INDICES_FILE = BASE_DIR / 'class_indices.json'

# Global Cache with LRU
MAX_MODELS = 10
loaded_models = OrderedDict()
class_indices = {}
translations = {}

# User sessions: {user_id: selected_crop}
user_sessions = {}

# Load resources
def load_resources():
    global class_indices, translations
    
    if TRANSLATIONS_FILE.exists():
        with open(TRANSLATIONS_FILE, 'r', encoding='utf-8') as f:
            translations = json.load(f)
        print("âœ… Translations Loaded")
    
    if INDICES_FILE.exists():
        with open(INDICES_FILE, 'r') as f:
            class_indices = json.load(f)
        print(f"âœ… Class Indices Loaded: {len(class_indices)} models")

# Model loading with LRU cache
def get_model(model_name):
    if model_name in loaded_models:
        loaded_models.move_to_end(model_name)
        print(f"â™»ï¸ Using cached model: {model_name}")
        return loaded_models[model_name]
    
    model_path = MODELS_DIR / f"{model_name}_final.keras"
    
    if not model_path.exists():
        print(f"âŒ Model not found: {model_path}")
        return None
    
    if len(loaded_models) >= MAX_MODELS:
        oldest = next(iter(loaded_models))
        print(f"ğŸ—‘ï¸ Removing old model: {oldest}")
        del loaded_models[oldest]
        gc.collect()
    
    print(f"ğŸ“¥ Loading model: {model_name}... ({len(loaded_models)+1}/{MAX_MODELS})")
    model = tf.keras.models.load_model(model_path)
    loaded_models[model_name] = model
    print(f"âœ… Model loaded: {model_name}")
    
    return model

# Prediction
def predict_image(model, img_data, model_name):
    img = Image.open(BytesIO(img_data)).convert('RGB').resize((224, 224))
    img_array = np.array(img).astype('float32')
    img_array = np.expand_dims(img_array, axis=0)
    img_array = tf.keras.applications.efficientnet.preprocess_input(img_array)
    
    predictions = model.predict(img_array, verbose=0)
    predicted_class_idx = np.argmax(predictions[0])
    confidence = float(predictions[0][predicted_class_idx] * 100)
    
    indices = class_indices.get(model_name, {})
    english_label = indices.get(str(predicted_class_idx), f"Class_{predicted_class_idx}")
    
    crop_name = model_name.replace('_', ' ').title()
    arabic_label = english_label
    
    if crop_name in translations and english_label in translations[crop_name]:
        arabic_label = translations[crop_name][english_label]
        
    return arabic_label, confidence

# Telegram Bot Handlers

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Handle /start command"""
    user_id = update.effective_user.id
    user_sessions.pop(user_id, None)
    
    keyboard = [
        ['ğŸŒ´ Ù†Ø®ÙŠÙ„ - Ø£ÙˆØ±Ø§Ù‚', 'ğŸŠ Ø­Ù…Ø¶ÙŠØ§Øª - Ø«Ù…Ø§Ø±'],
        ['ğŸƒ Ø­Ù…Ø¶ÙŠØ§Øª - Ø£ÙˆØ±Ø§Ù‚', 'ğŸ… Ø·Ù…Ø§Ø·Ù… - Ø£ÙˆØ±Ø§Ù‚'],
        ['ğŸ¥” Ø¨Ø·Ø§Ø·Ø³ - Ø£ÙˆØ±Ø§Ù‚', 'ğŸ¥’ Ø®ÙŠØ§Ø± - Ø£ÙˆØ±Ø§Ù‚'],
        ['ğŸŒ½ Ø°Ø±Ø© - Ø£ÙˆØ±Ø§Ù‚', 'ğŸ‡ Ø¹Ù†Ø¨ - Ø£ÙˆØ±Ø§Ù‚'],
        ['ğŸ Ø±Ù…Ø§Ù† - Ø«Ù…Ø§Ø±', 'ğŸ¥¬ Ø®Ø³ - Ø£ÙˆØ±Ø§Ù‚'],
        ['ğŸŒ¾ Ù‚Ù…Ø­ - Ø£ÙˆØ±Ø§Ù‚', 'ğŸ¥­ Ù…Ø§Ù†Ø¬Ùˆ - Ø£ÙˆØ±Ø§Ù‚'],
        ['ğŸŒ Ù…ÙˆØ² - Ø«Ù…Ø§Ø±', 'ğŸƒ Ù…ÙˆØ² - Ø£ÙˆØ±Ø§Ù‚'],
        ['ğŸ«˜ ÙØ§ØµÙˆÙ„ÙŠØ§ - Ø£ÙˆØ±Ø§Ù‚', 'ğŸ† Ø¨Ø§Ø°Ù†Ø¬Ø§Ù† - Ø£ÙˆØ±Ø§Ù‚'],
        ['ğŸ¥— Ù…Ù„ÙÙˆÙ - Ø£ÙˆØ±Ø§Ù‚', 'ğŸŒ¶ï¸ ÙÙ„ÙÙ„ - Ø£ÙˆØ±Ø§Ù‚']
    ]
    
    reply_markup = ReplyKeyboardMarkup(keyboard, resize_keyboard=True, one_time_keyboard=False)
    
    await update.message.reply_text(
        "ğŸŒ¿ *Ø£Ù‡Ù„Ø§Ù‹ Ø¨Ùƒ ÙÙŠ Ø·Ø¨ÙŠØ¨ Ø§Ù„Ù†Ø¨Ø§ØªØ§Øª Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ!* ğŸ‡¸ğŸ‡¦\n\n"
        "Ø§Ø®ØªØ± Ø§Ù„Ù…Ø­ØµÙˆÙ„ Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©:",
        reply_markup=reply_markup,
        parse_mode='Markdown'
    )

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Handle crop selection"""
    user_id = update.effective_user.id
    text = update.message.text
    
    # Crop mapping
    crop_map = {
        'ğŸŒ´ Ù†Ø®ÙŠÙ„ - Ø£ÙˆØ±Ø§Ù‚': 'date_palm_leaves',
        'ğŸŠ Ø­Ù…Ø¶ÙŠØ§Øª - Ø«Ù…Ø§Ø±': 'citrus_fruits',
        'ğŸƒ Ø­Ù…Ø¶ÙŠØ§Øª - Ø£ÙˆØ±Ø§Ù‚': 'citrus_leaves',
        'ğŸ… Ø·Ù…Ø§Ø·Ù… - Ø£ÙˆØ±Ø§Ù‚': 'tomato_leaves',
        'ğŸ¥” Ø¨Ø·Ø§Ø·Ø³ - Ø£ÙˆØ±Ø§Ù‚': 'potato_leaves',
        'ğŸ¥’ Ø®ÙŠØ§Ø± - Ø£ÙˆØ±Ø§Ù‚': 'cucumber_leaves',
        'ğŸŒ½ Ø°Ø±Ø© - Ø£ÙˆØ±Ø§Ù‚': 'corn_leaves',
        'ğŸ‡ Ø¹Ù†Ø¨ - Ø£ÙˆØ±Ø§Ù‚': 'grape_leaves',
        'ğŸ Ø±Ù…Ø§Ù† - Ø«Ù…Ø§Ø±': 'pomegranate_fruits',
        'ğŸ¥¬ Ø®Ø³ - Ø£ÙˆØ±Ø§Ù‚': 'lettuce_leaves',
        'ğŸŒ¾ Ù‚Ù…Ø­ - Ø£ÙˆØ±Ø§Ù‚': 'wheat_leaves',
        'ğŸ¥­ Ù…Ø§Ù†Ø¬Ùˆ - Ø£ÙˆØ±Ø§Ù‚': 'mango_leaves',
        'ğŸŒ Ù…ÙˆØ² - Ø«Ù…Ø§Ø±': 'banana_fruits',
        'ğŸƒ Ù…ÙˆØ² - Ø£ÙˆØ±Ø§Ù‚': 'banana_leaves',
        'ğŸ«˜ ÙØ§ØµÙˆÙ„ÙŠØ§ - Ø£ÙˆØ±Ø§Ù‚': 'bean_leaves',
        'ğŸ† Ø¨Ø§Ø°Ù†Ø¬Ø§Ù† - Ø£ÙˆØ±Ø§Ù‚': 'eggplant_leaves',
        'ğŸ¥— Ù…Ù„ÙÙˆÙ - Ø£ÙˆØ±Ø§Ù‚': 'cabbage_leaves',
        'ğŸŒ¶ï¸ ÙÙ„ÙÙ„ - Ø£ÙˆØ±Ø§Ù‚': 'pepper_leaves'
    }
    
    if text in crop_map:
        selected_crop = crop_map[text]
        user_sessions[user_id] = selected_crop
        
        sample_type = 'Ø§Ù„Ø«Ù…Ø±Ø©' if 'fruits' in selected_crop else 'Ø§Ù„ÙˆØ±Ù‚Ø©'
        
        await update.message.reply_text(
            f"âœ… ØªÙ… Ø§Ø®ØªÙŠØ§Ø±: *{text}*\n\n"
            f"ğŸ“¸ *Ø§Ù„Ø¢Ù†ØŒ Ø£Ø±Ø³Ù„ ØµÙˆØ±Ø© {sample_type} Ø§Ù„Ù…ØµØ§Ø¨Ø©.*",
            parse_mode='Markdown'
        )
    else:
        await update.message.reply_text(
            "âš ï¸ Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ø®ØªÙŠØ§Ø± Ù…Ø­ØµÙˆÙ„ Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø£ÙˆÙ„Ø§Ù‹ØŒ Ø£Ùˆ Ø§Ø¶ØºØ· /start"
        )

async def handle_photo(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Handle photo uploads"""
    user_id = update.effective_user.id
    
    if user_id not in user_sessions:
        await update.message.reply_text(
            "âš ï¸ *Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…Ø­ØµÙˆÙ„ Ø£ÙˆÙ„Ø§Ù‹!*\nØ§Ø¶ØºØ· /start",
            parse_mode='Markdown'
        )
        return
    
    current_crop = user_sessions[user_id]
    
    try:
        # Get the photo
        photo = update.message.photo[-1]  # Highest resolution
        file = await context.bot.get_file(photo.file_id)
        
        # Download image data
        img_bytes = await file.download_as_bytearray()
        img_data = bytes(img_bytes)
        
        print(f"ğŸ“¥ Image received from user {user_id}: {len(img_data)} bytes")
        
        # Load model
        model = get_model(current_crop)
        if not model:
            await update.message.reply_text("âŒ Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ØºÙŠØ± Ù…ØªÙˆÙØ± Ø­Ø§Ù„ÙŠØ§Ù‹.")
            return
        
        # Predict
        print(f"ğŸ”¬ Analyzing image...")
        diagnosis, conf = predict_image(model, img_data, current_crop)
        print(f"   âœ… Result: {diagnosis} ({conf:.1f}%)")
        
        # Escape HTML special characters in diagnosis
        diagnosis_escaped = diagnosis.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')
        
        # Build result with HTML formatting
        result_text = f"ğŸ” <b>Ø§Ù„ØªØ´Ø®ÙŠØµ:</b> {diagnosis_escaped}\nğŸ¯ <b>Ø§Ù„Ø¯Ù‚Ø©:</b> {conf:.1f}%\n\n"
        
        if conf < 60:
            result_text += "âš ï¸ <b>Ù…Ù„Ø§Ø­Ø¸Ø©:</b> Ù„Ø³Øª Ù…ØªØ£ÙƒØ¯Ø§Ù‹ ØªÙ…Ø§Ù…Ø§Ù‹. ÙŠØ±Ø¬Ù‰ Ø§Ø³ØªØ´Ø§Ø±Ø© Ù…Ù‡Ù†Ø¯Ø³ Ø²Ø±Ø§Ø¹ÙŠ."
        else:
            result_text += "âœ… <b>Ø§Ù„ØªØ´Ø®ÙŠØµ Ù…ÙˆØ«ÙˆÙ‚.</b>"
        
        await update.message.reply_text(result_text, parse_mode='HTML')
        print(f"âœ… Sent reply to user {user_id}")
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()
        await update.message.reply_text("âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©. Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.")

def main():
    """Start the bot"""
    # Load resources
    load_resources()
    
    # Get bot token from environment variable ONLY
    TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')
    
    if not TOKEN:
        raise ValueError("âŒ TELEGRAM_BOT_TOKEN must be set in environment variables!")
    
    # Get port and webhook URL
    PORT = int(os.environ.get('PORT', 10000))
    WEBHOOK_URL = os.environ.get('WEBHOOK_URL', 'https://plant-bot-yqxl.onrender.com')
    
    # Create Telegram application
    application = Application.builder().token(TOKEN).build()
    
    # Add handlers
    application.add_handler(CommandHandler("start", start))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    application.add_handler(MessageHandler(filters.PHOTO, handle_photo))
    
    # Flask app for webhook
    app = Flask(__name__)
    
    @app.route('/')
    def index():
        return 'Telegram Bot is running!', 200
    
    @app.route('/health')
    def health():
        return 'OK', 200
    
    @app.route(f'/{TOKEN}', methods=['POST'])
    def telegram_webhook():
        """Handle incoming updates via webhook"""
        try:
            update = Update.de_json(request.get_json(force=True), application.bot)
            # Run async code in sync context
            import asyncio
            asyncio.run(application.process_update(update))
            return 'OK'
        except Exception as e:
            print(f"âŒ Webhook error: {e}")
            import traceback
            traceback.print_exc()
            return 'Error', 500
    
    # Set webhook
    async def set_webhook():
        webhook_url = f"{WEBHOOK_URL}/{TOKEN}"
        await application.bot.set_webhook(url=webhook_url)
        print(f"âœ… Webhook set to: {webhook_url}")
    
    # Initialize bot
    import asyncio
    asyncio.run(set_webhook())
    
    print(f"âœ… Telegram bot started with webhook!")
    print(f"âœ… Server running on port {PORT}")
    
    # Run Flask app
    app.run(host='0.0.0.0', port=PORT, debug=False)

if __name__ == '__main__':
    main()
