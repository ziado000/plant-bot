import os
import requests
import numpy as np
import tensorflow as tf
import json
from pathlib import Path
from PIL import Image
from io import BytesIO
from collections import OrderedDict
import gc
import zipfile

# Telegram imports
from telegram import Update, ReplyKeyboardMarkup
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes

# Statistics logging
from bot_statistics import log_prediction, initialize_stats_file

# Download models from Dropbox
def download_models_from_dropbox():
    models_dir = Path('models')
    
    print(f"ğŸ” Checking models directory...")
    print(f"   Directory exists: {models_dir.exists()}")
    
    if models_dir.exists():
        model_files = list(models_dir.glob('*.keras'))
        print(f"   Found {len(model_files)} .keras files")
        if len(model_files) >= 18:
            print("âœ… All 18 models exist, skipping download")
            return
        else:
            print(f"âš ï¸ Only {len(model_files)}/18 models found, downloading...")
    else:
        print("   Models directory doesn't exist, creating and downloading...")
    
    print("ğŸ“¥ Downloading models from Hugging Face...")
    
    HUGGINGFACE_URL = "https://huggingface.co/ziadabdullah/saudi-plant-disease-models/resolve/main/models.zip"
    
    try:
        print("â¬ Starting download... (this may take 5-10 minutes)")
        
        response = requests.get(HUGGINGFACE_URL, stream=True)
        response.raise_for_status()  # Raise error for bad status codes
        
        print(f"   Download response status: {response.status_code}")
        
        with open("models.zip", 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                f.write(chunk)
        
        print("âœ… Download complete!")
        print("ğŸ“¦ Extracting models.zip...")
        
        # Extract
        with zipfile.ZipFile("models.zip", 'r') as z:
            file_list = z.namelist()
            print(f"   Extracting {len(file_list)} files...")
            z.extractall('.')
        
        os.remove("models.zip")
        
        # Find models - check both root and nested directories
        model_files = list(Path('.').rglob('*.keras'))
        print(f"   Found {len(model_files)} .keras files")
        
        # Move models to correct location if they're nested
        if model_files and not models_dir.exists():
            models_dir.mkdir(exist_ok=True)
        
        for model_file in model_files:
            if model_file.parent != models_dir:
                target = models_dir / model_file.name
                print(f"   Moving {model_file.name} to models/")
                model_file.rename(target)
        
        # Verify final count
        final_count = len(list(models_dir.glob('*.keras')))
        print(f"âœ… Models ready! ({final_count} files in models/ directory)")
        
        if final_count < 18:
            print(f"âš ï¸ Warning: Expected 18 models, only found {final_count}")
        
    except Exception as e:
        print(f"âŒ Download Error: {e}")
        import traceback
        traceback.print_exc()

# Paths
BASE_DIR = Path('.')
MODELS_DIR = BASE_DIR / 'models'

# Download models on startup
download_models_from_dropbox()

# Check for local files
if Path('disease_translations.json').exists():
    TRANSLATIONS_FILE = Path('disease_translations.json')
else:
    TRANSLATIONS_FILE = BASE_DIR / 'disease_translations.json'

if Path('class_indices.json').exists():
    INDICES_FILE = Path('class_indices.json')
else:
    INDICES_FILE = BASE_DIR / 'class_indices.json'

# Global Cache with LRU
MAX_MODELS = 10
loaded_models = OrderedDict()
class_indices = {}
translations = {}

# User sessions
user_sessions = {}

# Load resources
def load_resources():
    global class_indices, translations
    
    if TRANSLATIONS_FILE.exists():
        with open(TRANSLATIONS_FILE, 'r', encoding='utf-8') as f:
            translations = json.load(f)
        print("âœ… Translations Loaded")
    
    if INDICES_FILE.exists():
        with open(INDICES_FILE, 'r') as f:
            class_indices = json.load(f)
        print(f"âœ… Class Indices Loaded: {len(class_indices)} models")

# Model loading with LRU cache
def get_model(model_name):
    if model_name in loaded_models:
        loaded_models.move_to_end(model_name)
        print(f"â™»ï¸ Using cached model: {model_name}")
        return loaded_models[model_name]
    
    model_path = MODELS_DIR / f"{model_name}_final.keras"
    
    if not model_path.exists():
        print(f"âŒ Model not found: {model_path}")
        return None
    
    if len(loaded_models) >= MAX_MODELS:
        oldest = next(iter(loaded_models))
        print(f"ğŸ—‘ï¸ Removing old model: {oldest}")
        del loaded_models[oldest]
        gc.collect()
    
    print(f"ğŸ“¥ Loading model: {model_name}... ({len(loaded_models)+1}/{MAX_MODELS})")
    model = tf.keras.models.load_model(model_path)
    loaded_models[model_name] = model
    print(f"âœ… Model loaded: {model_name}")
    
    return model

# Prediction
def predict_image(model, img_data, model_name):
    img = Image.open(BytesIO(img_data)).convert('RGB').resize((224, 224))
    img_array = np.array(img).astype('float32')
    img_array = np.expand_dims(img_array, axis=0)
    img_array = tf.keras.applications.efficientnet.preprocess_input(img_array)
    
    predictions = model.predict(img_array, verbose=0)
    predicted_class_idx = np.argmax(predictions[0])
    confidence = float(predictions[0][predicted_class_idx] * 100)
    
    indices = class_indices.get(model_name, {})
    english_label = indices.get(str(predicted_class_idx), f"Class_{predicted_class_idx}")
    
    print(f"   ğŸ” Translation lookup: model={model_name}, label={english_label}")
    
    # Get bilingual label (Arabic + English)
    bilingual_label = english_label  # Default to English only
    
    # Try multiple matching strategies
    found = False
    
    # Strategy 1: Exact match
    if model_name in translations and english_label in translations[model_name]:
        bilingual_label = translations[model_name][english_label]
        found = True
        print(f"   âœ… Found exact match: {bilingual_label}")
    
    # Strategy 2: Lowercase with underscores
    if not found:
        english_lower = english_label.lower().replace(' ', '_')
        if model_name in translations and english_lower in translations[model_name]:
            bilingual_label = translations[model_name][english_lower]
            found = True
            print(f"   âœ… Found lowercase match: {bilingual_label}")
    
    # Strategy 3: Try just lowercase
    if not found:
        english_simple_lower = english_label.lower()
        if model_name in translations and english_simple_lower in translations[model_name]:
            bilingual_label = translations[model_name][english_simple_lower]
            found = True
            print(f"   âœ… Found simple lowercase: {bilingual_label}")
    
    if not found:
        print(f"   âš ï¸ No translation found, using English only")
        # Show what keys are available for debugging
        if model_name in translations:
            available_keys = list(translations[model_name].keys())[:3]
            print(f"   Available keys: {available_keys}...")
    
    # If translation doesn't include English in parentheses, add it
    if english_label not in bilingual_label and '(' not in bilingual_label:
        bilingual_label = f"{bilingual_label} ({english_label})"
        
    return bilingual_label, confidence

# Telegram Bot Handlers

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Handle /start command"""
    user_id = update.effective_user.id
    user_sessions.pop(user_id, None)
    
    keyboard = [
        ['ğŸŒ´ Ù†Ø®ÙŠÙ„ - Ø£ÙˆØ±Ø§Ù‚', 'ğŸŠ Ø­Ù…Ø¶ÙŠØ§Øª - Ø«Ù…Ø§Ø±'],
        ['ğŸƒ Ø­Ù…Ø¶ÙŠØ§Øª - Ø£ÙˆØ±Ø§Ù‚', 'ğŸ… Ø·Ù…Ø§Ø·Ù… - Ø£ÙˆØ±Ø§Ù‚'],
        ['ğŸ¥” Ø¨Ø·Ø§Ø·Ø³ - Ø£ÙˆØ±Ø§Ù‚', 'ğŸ¥’ Ø®ÙŠØ§Ø± - Ø£ÙˆØ±Ø§Ù‚'],
        ['ğŸŒ½ Ø°Ø±Ø© - Ø£ÙˆØ±Ø§Ù‚', 'ğŸ‡ Ø¹Ù†Ø¨ - Ø£ÙˆØ±Ø§Ù‚'],
        ['ğŸ Ø±Ù…Ø§Ù† - Ø«Ù…Ø§Ø±', 'ğŸ¥¬ Ø®Ø³ - Ø£ÙˆØ±Ø§Ù‚'],
        ['ğŸŒ¾ Ù‚Ù…Ø­ - Ø£ÙˆØ±Ø§Ù‚', 'ğŸ¥­ Ù…Ø§Ù†Ø¬Ùˆ - Ø£ÙˆØ±Ø§Ù‚'],
        ['ğŸŒ Ù…ÙˆØ² - Ø«Ù…Ø§Ø±', 'ğŸƒ Ù…ÙˆØ² - Ø£ÙˆØ±Ø§Ù‚'],
        ['ğŸ«˜ ÙØ§ØµÙˆÙ„ÙŠØ§ - Ø£ÙˆØ±Ø§Ù‚', 'ğŸ† Ø¨Ø§Ø°Ù†Ø¬Ø§Ù† - Ø£ÙˆØ±Ø§Ù‚'],
        ['ğŸ¥— Ù…Ù„ÙÙˆÙ - Ø£ÙˆØ±Ø§Ù‚', 'ğŸŒ¶ï¸ ÙÙ„ÙÙ„ - Ø£ÙˆØ±Ø§Ù‚']
    ]
    
    reply_markup = ReplyKeyboardMarkup(keyboard, resize_keyboard=True, one_time_keyboard=False)
    
    await update.message.reply_text(
        "ğŸŒ¿ Ø£Ù‡Ù„Ø§Ù‹ Ø¨Ùƒ ÙÙŠ Ø·Ø¨ÙŠØ¨ Ø§Ù„Ù†Ø¨Ø§ØªØ§Øª Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ! ğŸ‡¸ğŸ‡¦\n\n"
        "Ø§Ø®ØªØ± Ø§Ù„Ù…Ø­ØµÙˆÙ„ Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©:",
        reply_markup=reply_markup
    )

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Handle crop selection"""
    user_id = update.effective_user.id
    text = update.message.text
    
    # Crop mapping
    crop_map = {
        'ğŸŒ´ Ù†Ø®ÙŠÙ„ - Ø£ÙˆØ±Ø§Ù‚': 'date_palm_leaves',
        'ğŸŠ Ø­Ù…Ø¶ÙŠØ§Øª - Ø«Ù…Ø§Ø±': 'citrus_fruits',
        'ğŸƒ Ø­Ù…Ø¶ÙŠØ§Øª - Ø£ÙˆØ±Ø§Ù‚': 'citrus_leaves',
        'ğŸ… Ø·Ù…Ø§Ø·Ù… - Ø£ÙˆØ±Ø§Ù‚': 'tomato_leaves',
        'ğŸ¥” Ø¨Ø·Ø§Ø·Ø³ - Ø£ÙˆØ±Ø§Ù‚': 'potato_leaves',
        'ğŸ¥’ Ø®ÙŠØ§Ø± - Ø£ÙˆØ±Ø§Ù‚': 'cucumber_leaves',
        'ğŸŒ½ Ø°Ø±Ø© - Ø£ÙˆØ±Ø§Ù‚': 'corn_leaves',
        'ğŸ‡ Ø¹Ù†Ø¨ - Ø£ÙˆØ±Ø§Ù‚': 'grape_leaves',
        'ğŸ Ø±Ù…Ø§Ù† - Ø«Ù…Ø§Ø±': 'pomegranate_fruits',
        'ğŸ¥¬ Ø®Ø³ - Ø£ÙˆØ±Ø§Ù‚': 'lettuce_leaves',
        'ğŸŒ¾ Ù‚Ù…Ø­ - Ø£ÙˆØ±Ø§Ù‚': 'wheat_leaves',
        'ğŸ¥­ Ù…Ø§Ù†Ø¬Ùˆ - Ø£ÙˆØ±Ø§Ù‚': 'mango_leaves',
        'ğŸŒ Ù…ÙˆØ² - Ø«Ù…Ø§Ø±': 'banana_fruits',
        'ğŸƒ Ù…ÙˆØ² - Ø£ÙˆØ±Ø§Ù‚': 'banana_leaves',
        'ğŸ«˜ ÙØ§ØµÙˆÙ„ÙŠØ§ - Ø£ÙˆØ±Ø§Ù‚': 'bean_leaves',
        'ğŸ† Ø¨Ø§Ø°Ù†Ø¬Ø§Ù† - Ø£ÙˆØ±Ø§Ù‚': 'eggplant_leaves',
        'ğŸ¥— Ù…Ù„ÙÙˆÙ - Ø£ÙˆØ±Ø§Ù‚': 'cabbage_leaves',
        'ğŸŒ¶ï¸ ÙÙ„ÙÙ„ - Ø£ÙˆØ±Ø§Ù‚': 'pepper_leaves'
    }
    
    if text in crop_map:
        selected_crop = crop_map[text]
        user_sessions[user_id] = selected_crop
        
        sample_type = 'Ø§Ù„Ø«Ù…Ø±Ø©' if 'fruits' in selected_crop else 'Ø§Ù„ÙˆØ±Ù‚Ø©'
        
        await update.message.reply_text(
            f"âœ… ØªÙ… Ø§Ø®ØªÙŠØ§Ø±: {text}\n\n"
            f"ğŸ“¸ Ø§Ù„Ø¢Ù†ØŒ Ø£Ø±Ø³Ù„ ØµÙˆØ±Ø© {sample_type} Ø§Ù„Ù…ØµØ§Ø¨Ø©."
        )
    else:
        await update.message.reply_text(
            "âš ï¸ Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ø®ØªÙŠØ§Ø± Ù…Ø­ØµÙˆÙ„ Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø£ÙˆÙ„Ø§Ù‹ØŒ Ø£Ùˆ Ø§Ø¶ØºØ· /start"
        )

async def handle_photo(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Handle photo uploads"""
    user_id = update.effective_user.id
    
    if user_id not in user_sessions:
        await update.message.reply_text(
            "âš ï¸ Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…Ø­ØµÙˆÙ„ Ø£ÙˆÙ„Ø§Ù‹!\nØ§Ø¶ØºØ· /start"
        )
        return
    
    current_crop = user_sessions[user_id]
    
    try:
        # Get the photo
        photo = update.message.photo[-1]
        file = await context.bot.get_file(photo.file_id)
        
        # Download image data
        img_bytes = await file.download_as_bytearray()
        img_data = bytes(img_bytes)
        
        print(f"ğŸ“¥ Image received from user {user_id}: {len(img_data)} bytes")
        
        # Load model
        model = get_model(current_crop)
        if not model:
            await update.message.reply_text("âŒ Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ØºÙŠØ± Ù…ØªÙˆÙØ± Ø­Ø§Ù„ÙŠØ§Ù‹.")
            return
        
        # Predict
        print(f"ğŸ”¬ Analyzing image...")
        diagnosis, conf = predict_image(model, img_data, current_crop)
        print(f"   âœ… Result: {diagnosis} ({conf:.1f}%)")
        
        # Log statistics
        log_prediction(
            user_id=user_id,
            crop_type=current_crop,
            disease=diagnosis,
            confidence=conf,
            platform="Telegram"
        )
        
        # Escape HTML special characters
        diagnosis_escaped = diagnosis.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')
        
        # Build result with universal disclaimer
        result_text = (
            f"ğŸ” <b>Ø§Ù„ØªØ´Ø®ÙŠØµ:</b> {diagnosis_escaped}\n"
            f"ğŸ¯ <b>Ø§Ù„Ø¯Ù‚Ø©:</b> {conf:.1f}%\n\n"
            f"âš ï¸ <b>Ù…Ù„Ø§Ø­Ø¸Ø© Ù‡Ø§Ù…Ø©:</b> Ù‡Ø°Ø§ ØªØ´Ø®ÙŠØµ Ø£ÙˆÙ„ÙŠ Ù„Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ. "
            f"ÙŠÙÙ†ØµØ­ Ø¨Ø§Ø³ØªØ´Ø§Ø±Ø© Ù…Ù‡Ù†Ø¯Ø³ Ø²Ø±Ø§Ø¹ÙŠ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªØ´Ø®ÙŠØµ Ø¯Ù‚ÙŠÙ‚ ÙˆØ®Ø·Ø© Ø¹Ù„Ø§Ø¬ Ù…Ù†Ø§Ø³Ø¨Ø©.\n\n"
            f"<i>This is a preliminary diagnosis. Please consult an agricultural engineer for accurate diagnosis and treatment plan.</i>"
        )
        
        await update.message.reply_text(result_text, parse_mode='HTML')
        print(f"âœ… Sent reply to user {user_id}")
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()
        await update.message.reply_text("âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©. Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.")

def main():
    """Start the bot"""
    # Load resources
    load_resources()
    
    # Initialize statistics logging
    initialize_stats_file()
    
    # Get bot token from environment
    TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')
    
    if not TOKEN:
        raise ValueError("âŒ TELEGRAM_BOT_TOKEN environment variable is not set!")
    
    # Validate token length (Telegram tokens are typically 45-46 characters)
    if len(TOKEN) < 45:
        raise ValueError(
            f"âŒ TELEGRAM_BOT_TOKEN appears to be truncated!\n"
            f"   Current length: {len(TOKEN)} characters\n"
            f"   Expected: 45+ characters\n"
            f"   Token starts with: {TOKEN[:20]}...\n"
            f"   Please check your environment variable on Render!"
        )
    
    print(f"âœ… Token validated (length: {len(TOKEN)} characters)")
    
    # Create application with increased timeouts for slower networks
    from telegram.request import HTTPXRequest
    
    # Configure request with longer timeouts (Render can be slow)
    request = HTTPXRequest(
        connection_pool_size=8,
        connect_timeout=30.0,    # 30 seconds to connect
        read_timeout=60.0,       # 60 seconds to read data
        write_timeout=60.0,      # 60 seconds to write data
        pool_timeout=30.0        # 30 seconds to get connection from pool
    )
    
    application = Application.builder().token(TOKEN).request(request).build()

    
    # Set up bot commands menu (appears when user types "/")
    async def post_init(app: Application):
        """Set bot commands after initialization"""
        from telegram import BotCommand
        await app.bot.set_my_commands([
            BotCommand("start", "ğŸŒ¿ Ø§Ø¨Ø¯Ø£ Ù…Ù† Ø¬Ø¯ÙŠØ¯ - Start over"),
            BotCommand("help", "â“ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© - Get help"),
        ])
        print("âœ… Bot commands menu configured")
    
    application.post_init = post_init
    
    # Add handlers
    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("help", start))  # Help = Start
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    application.add_handler(MessageHandler(filters.PHOTO, handle_photo))
    
    # Start bot with polling
    print("âœ… Telegram bot started with polling!")
    application.run_polling(allowed_updates=Update.ALL_TYPES, drop_pending_updates=True)

if __name__ == '__main__':
    main()
